{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792af211",
   "metadata": {},
   "source": [
    "# Product Generate Article from Categories of the products\n",
    "## Take the clusters and make a summary of all the reviews of each group\n",
    "---\n",
    "**Objective:** create a model that generates a short article (like a blog post) for each product category.\n",
    "\n",
    "**Approach:**\n",
    "1. Define the Evidence Layer\n",
    "2. Use the classification\n",
    "3. Use the clusters\n",
    "4. Determine Top 3 Products\n",
    "5. Determine Worst Product\n",
    "6. Compute Key Differences\n",
    "7. Build the Category Evidence Pack\n",
    "8. Generate `.csv`\n",
    "9. Create a Gradio app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6474a",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab4806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aed8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffe276",
   "metadata": {},
   "source": [
    "## 2. Load & Merge the Data from the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93736973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 28,332 reviews, 6 unique clusters\n",
      "Dataset: 28,332 reviews, 3 unique sentiments\n"
     ]
    }
   ],
   "source": [
    "df_sentiment = pd.read_csv(\"data_with_predictions_v2.csv\")\n",
    "df_clusters = pd.read_csv(\"data_with_clusters.csv\")\n",
    "print(f'Dataset: {len(df_clusters):,} reviews, {df_clusters[\"cluster\"].nunique()} unique clusters')\n",
    "print(f'Dataset: {len(df_sentiment):,} reviews, {df_sentiment[\"predicted_label\"].nunique()} unique sentiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd5aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_cols = [\"id\", \"reviews.text\", \"reviews.date\", \"reviews.username\"]\n",
    "\n",
    "df = df_clusters.merge(df_sentiment[ merge_cols + [\n",
    "                                                    \"predicted_label\",\n",
    "                                                    \"predicted_score\",\n",
    "                                                    \"score_negative\",\n",
    "                                                    \"score_neutral\",\n",
    "                                                    \"score_positive\"\n",
    "                                                    ]\n",
    "                                    ],\n",
    "                        on=merge_cols,\n",
    "                        how=\"left\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].str.upper().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "939afdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'asins', 'brand', 'categories', 'primaryCategories',\n",
       "       'manufacturer', 'reviews.date', 'reviews.doRecommend',\n",
       "       'reviews.numHelpful', 'reviews.rating', 'reviews.text', 'reviews.title',\n",
       "       'reviews.username', 'sentiment', 'review_length', 'review_word_count',\n",
       "       'dateAdded_parsed', 'dateUpdated_parsed', 'reviews.date_parsed',\n",
       "       'reviews.dateSeen_parsed', 'cluster', 'cluster_name', 'predicted_label',\n",
       "       'predicted_score', 'score_negative', 'score_neutral', 'score_positive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383a34b",
   "metadata": {},
   "source": [
    "## 3. Obtaining the top 3 and the worst products plus briefing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COL = \"cluster_name\"\n",
    "PROD_COL = \"name\"\n",
    "TEXT_COL = \"reviews.text\"\n",
    "\n",
    "\n",
    "product_stats = (\n",
    "    df.groupby([CAT_COL, PROD_COL])\n",
    "      .agg(\n",
    "          review_count=(TEXT_COL, \"count\"),\n",
    "          avg_rating=(\"reviews.rating\", \"mean\"),\n",
    "          neg_rate=(\"score_negative\", \"mean\"),\n",
    "          pos_rate=(\"score_positive\", \"mean\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# ranking score: rating plus confidence, weighted by volume\n",
    "product_stats[\"rank_score\"] = product_stats[\"avg_rating\"] * np.log1p(product_stats[\"review_count\"])\n",
    "\n",
    "top3 = (\n",
    "    product_stats.sort_values([CAT_COL, \"rank_score\"], ascending=[True, False])\n",
    "    .groupby(CAT_COL).head(3)\n",
    ")\n",
    "\n",
    "min_reviews = 20\n",
    "worst = (\n",
    "    product_stats[product_stats[\"review_count\"] >= min_reviews]\n",
    "    .sort_values([CAT_COL, \"avg_rating\"], ascending=[True, True])\n",
    "    .groupby(CAT_COL).head(1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_complaints_for_product(texts, topn=8):\n",
    "    '''basic cleanup and fetching the top products complaints'''\n",
    "    texts = [t for t in texts if isinstance(t, str) and t.strip()]\n",
    "    if len(texts) < 5:\n",
    "        return []\n",
    "\n",
    "    vec = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.95\n",
    "    )\n",
    "    X = vec.fit_transform(texts)\n",
    "    scores = X.mean(axis=0).A1\n",
    "    terms = np.array(vec.get_feature_names_out())\n",
    "    top_idx = scores.argsort()[::-1][:topn]\n",
    "    return terms[top_idx].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_product_complaints(df, category, product, topn=6):\n",
    "    '''fetches the complaints'''\n",
    "    neg_texts = df[\n",
    "        (df[CAT_COL] == category) &\n",
    "        (df[PROD_COL] == product) &\n",
    "        (df[\"predicted_label\"] == \"NEGATIVE\")\n",
    "    ][TEXT_COL].tolist()\n",
    "    return top_complaints_for_product(neg_texts, topn=topn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_category_brief(category):\n",
    "    '''build a in the right format'''\n",
    "    t3 = top3[top3[CAT_COL] == category]\n",
    "    w  = worst[worst[CAT_COL] == category]\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"CATEGORY: {category}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"TOP 3 PRODUCTS:\")\n",
    "\n",
    "    for i, row in enumerate(t3.itertuples(index=False), 1):\n",
    "        complaints = get_top_product_complaints(df, category, getattr(row, PROD_COL), topn=5)\n",
    "        lines.append(f\"{i}) {getattr(row, PROD_COL)} | rating={row.avg_rating:.2f} | reviews={int(row.review_count)}\")\n",
    "        if complaints:\n",
    "            lines.append(\"   complaints: \" + \"; \".join(complaints))\n",
    "        else:\n",
    "            lines.append(\"   complaints: (not enough negative reviews)\")\n",
    "\n",
    "    if len(w):\n",
    "        wr = w.iloc[0]\n",
    "        worst_complaints = get_top_product_complaints(df, category, wr[PROD_COL], topn=6)\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"WORST PRODUCT: {wr[PROD_COL]} | rating={wr.avg_rating:.2f} | reviews={int(wr.review_count)}\")\n",
    "        lines.append(\"avoid because: \" + (\"; \".join(worst_complaints) if worst_complaints else \"low ratings / frequent negatives\"))\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93f6e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accessories', 'Batteries & Household', 'E-Readers', 'Fire Tablets', 'Media & Home']\n",
      "\n",
      "--- SAMPLE BRIEF ---\n",
      "\n",
      "CATEGORY: Accessories\n",
      "\n",
      "TOP 3 PRODUCTS:\n",
      "1) Amazon 9W PowerFast Official OEM USB Charger and Power Adapter for Fire Tablets and Kindle eReaders | rating=4.67 | reviews=39\n",
      "   complaints: (not enough negative reviews)\n",
      "2) AmazonBasics 15.6-Inch Laptop and Tablet Bag | rating=4.52 | reviews=21\n",
      "   complaints: (not enough negative reviews)\n",
      "3) AmazonBasics Ventilated Adjustable Laptop Stand | rating=4.33 | reviews=24\n",
      "   complaints: (not enough negative reviews)\n",
      "\n",
      "WORST PRODUCT: AmazonBasics Backpack for Laptops up to 17-inches | rating=4.16 | reviews=25\n",
      "avoid because: low ratings / frequent negatives\n"
     ]
    }
   ],
   "source": [
    "categories = sorted(df[CAT_COL].dropna().unique().tolist())\n",
    "\n",
    "briefs = {cat: build_category_brief(cat) for cat in categories}\n",
    "\n",
    "# quick check\n",
    "print(categories[:5])\n",
    "print(\"\\n--- SAMPLE BRIEF ---\\n\")\n",
    "print(briefs[categories[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cc02e",
   "metadata": {},
   "source": [
    "## 4. Using T5 to create our summaries with a little of prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa36f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 282/282 [00:01<00:00, 188.33it/s, Materializing param=shared.weight]                                                       \n",
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "source": [
    "gen_model_name = \"google/flan-t5-base\"  # or flan-t5-large if you have GPU RAM\n",
    "\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained(gen_model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gen_model = gen_model.to(device)\n",
    "\n",
    "def generate_article(brief):\n",
    "    '''prompt engineering to generate our article'''\n",
    "    prompt = f\"\"\"\n",
    "You are writing a short shopper-friendly blog post.\n",
    "\n",
    "Use ONLY the facts in the brief.\n",
    "Do NOT invent products or features.\n",
    "\n",
    "BRIEF:\n",
    "{brief}\n",
    "\n",
    "Return your answer in EXACTLY this format:\n",
    "\n",
    "===TITLE===\n",
    "<one line title>\n",
    "\n",
    "===SUMMARY===\n",
    "<2 short paragraphs, 3â€“5 sentences total>\n",
    "\n",
    "===TOP3===\n",
    "- Product â€” Rating â€” Reviews â€” Complaints\n",
    "- Product â€” Rating â€” Reviews â€” Complaints\n",
    "- Product â€” Rating â€” Reviews â€” Complaints\n",
    "\n",
    "===AVOID===\n",
    "- Worst product â€” Rating â€” Reviews\n",
    "- Reason: <from brief>\n",
    "\n",
    "Keep under 220 words.\n",
    "Do NOT omit any section.\n",
    "\"\"\"\n",
    "\n",
    "    inputs = gen_tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    ).to(device)\n",
    "\n",
    "    out_ids = gen_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=320,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "    text = gen_tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # ðŸ”¹ SECTION PARSING HAPPENS HERE ðŸ”¹\n",
    "    try:\n",
    "        title = text.split(\"===TITLE===\")[1].split(\"===SUMMARY===\")[0].strip()\n",
    "        summary = text.split(\"===SUMMARY===\")[1].split(\"===TOP3===\")[0].strip()\n",
    "        top3 = text.split(\"===TOP3===\")[1].split(\"===AVOID===\")[0].strip()\n",
    "        avoid = text.split(\"===AVOID===\")[1].strip()\n",
    "    except IndexError:\n",
    "        # fallback if model fails structure\n",
    "        return text\n",
    "\n",
    "    # You can now return structured content\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"summary\": summary,\n",
    "        \"top3\": top3,\n",
    "        \"avoid\": avoid\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698210e",
   "metadata": {},
   "source": [
    "## 5. Helper functions for cleaner code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a846d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaint_cache = {}\n",
    "\n",
    "def get_top_product_complaints_cached(df, category, product, topn=6):\n",
    "    '''fetches the complaints now cached'''\n",
    "    key = (category, product, topn)\n",
    "    if key in complaint_cache:\n",
    "        return complaint_cache[key]\n",
    "\n",
    "    neg_texts = df[\n",
    "        (df[CAT_COL] == category) &\n",
    "        (df[PROD_COL] == product) &\n",
    "        (df[\"predicted_label\"] == \"NEGATIVE\")\n",
    "    ][TEXT_COL].tolist()\n",
    "\n",
    "    complaints = top_complaints_for_product(neg_texts, topn=topn)\n",
    "    complaint_cache[key] = complaints\n",
    "    return complaints\n",
    "\n",
    "\n",
    "\n",
    "def get_negative_snippets(df, category, product, max_snippets=2, max_len=120):\n",
    "    '''fetches the negative snippets and clean it'''\n",
    "    neg_texts = df[\n",
    "        (df[CAT_COL] == category) &\n",
    "        (df[PROD_COL] == product) &\n",
    "        (df[\"predicted_label\"] == \"NEGATIVE\")\n",
    "    ][TEXT_COL].dropna().tolist()\n",
    "\n",
    "    snippets = []\n",
    "    for text in neg_texts[:10]: \n",
    "        cleaned = text.strip().replace(\"\\n\", \" \")\n",
    "        if len(cleaned) > 20:\n",
    "            snippets.append(cleaned[:max_len] + (\"...\" if len(cleaned) > max_len else \"\"))\n",
    "        if len(snippets) >= max_snippets:\n",
    "            break\n",
    "\n",
    "    return snippets\n",
    "\n",
    "\n",
    "def build_category_brief_stronger(category):\n",
    "    '''build a better brief in the right format'''\n",
    "    t3 = top3[top3[CAT_COL] == category]\n",
    "    w  = worst[worst[CAT_COL] == category]\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"CATEGORY: {category}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"TOP 3 PRODUCTS:\")\n",
    "\n",
    "    for i, row in enumerate(t3.itertuples(index=False), 1):\n",
    "        product_name = getattr(row, PROD_COL)\n",
    "\n",
    "        complaints = get_top_product_complaints_cached(df, category, product_name, topn=5)\n",
    "        snippets   = get_negative_snippets(df, category, product_name, max_snippets=2)\n",
    "\n",
    "        lines.append(\n",
    "            f\"{i}) {product_name} | \"\n",
    "            f\"rating={row.avg_rating:.2f} | \"\n",
    "            f\"reviews={int(row.review_count)} | \"\n",
    "            f\"pos_rate={row.pos_rate:.2f} | \"\n",
    "            f\"neg_rate={row.neg_rate:.2f}\"\n",
    "        )\n",
    "\n",
    "        if complaints:\n",
    "            lines.append(\"   top complaints: \" + \"; \".join(complaints))\n",
    "        else:\n",
    "            lines.append(\"   top complaints: (insufficient negative reviews)\")\n",
    "\n",
    "        if snippets:\n",
    "            lines.append(\"   sample negative feedback:\")\n",
    "            for s in snippets:\n",
    "                lines.append(f'      - \"{s}\"')\n",
    "\n",
    "        lines.append(\"\")\n",
    "\n",
    "    if len(w):\n",
    "        wr = w.iloc[0]\n",
    "        worst_name = wr[PROD_COL]\n",
    "        worst_complaints = get_top_product_complaints_cached(df, category, worst_name, topn=6)\n",
    "        worst_snippets   = get_negative_snippets(df, category, worst_name, max_snippets=2)\n",
    "\n",
    "        lines.append(\"WORST PRODUCT:\")\n",
    "        lines.append(\n",
    "            f\"{worst_name} | rating={wr.avg_rating:.2f} | \"\n",
    "            f\"reviews={int(wr.review_count)} | \"\n",
    "            f\"neg_rate={wr.neg_rate:.2f}\"\n",
    "        )\n",
    "\n",
    "        if worst_complaints:\n",
    "            lines.append(\"   avoid because: \" + \"; \".join(worst_complaints))\n",
    "        else:\n",
    "            lines.append(\"   avoid because: frequent negative sentiment\")\n",
    "\n",
    "        if worst_snippets:\n",
    "            lines.append(\"   example complaints:\")\n",
    "            for s in worst_snippets:\n",
    "                lines.append(f'      - \"{s}\"')\n",
    "\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1addcce",
   "metadata": {},
   "source": [
    "## 6. Generating articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033ae9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "brief",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "article",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3a33a63f-05cc-4a40-bbf2-87104e4e82e3",
       "rows": [
        [
         "0",
         "Accessories",
         "CATEGORY: Accessories\n\nTOP 3 PRODUCTS:\n1) Amazon 9W PowerFast Official OEM USB Charger and Power Adapter for Fire Tablets and Kindle eReaders | rating=4.67 | reviews=39\n   complaints: (not enough negative reviews)\n2) AmazonBasics 15.6-Inch Laptop and Tablet Bag | rating=4.52 | reviews=21\n   complaints: (not enough negative reviews)\n3) AmazonBasics Ventilated Adjustable Laptop Stand | rating=4.33 | reviews=24\n   complaints: (not enough negative reviews)\n\nWORST PRODUCT: AmazonBasics Backpack for Laptops up to 17-inches | rating=4.16 | reviews=25\navoid because: low ratings / frequent negatives",
         "Amazon 9W PowerFast Official OEM USB Charger and Power Adapter for Fire Tablets and Kindle eReaders | rating=4.67 | reviews=39 complaints: (not enough negative reviews) AmazonBasics 15.6-Inch Laptop and Tablet Bag | rating=4.52 | reviews=21 complaints: (not enough negative reviews) AmazonBasics Ventilated Adjustable Laptop Stand | rating=4.33 | reviews=24 complaints: (not enough negative reviews) AmazonBasics Backpack for Laptops up to 17-inches | rating=4.16 | reviews=25 avoid because: low ratings / frequent negatives"
        ],
        [
         "1",
         "Batteries & Household",
         "CATEGORY: Batteries & Household\n\nTOP 3 PRODUCTS:\n1) AmazonBasics AAA Performance Alkaline Batteries (36 Count) | rating=4.45 | reviews=8343\n   complaints: batteries; long; don; battery; amazon\n2) AmazonBasics AA Performance Alkaline Batteries (48 Count) - Packaging May Vary | rating=4.45 | reviews=3728\n   complaints: batteries; long; don; battery; amazon\n3) Expanding Accordion File Folder Plastic Portable Document Organizer Letter Size | rating=5.00 | reviews=9\n   complaints: (not enough negative reviews)\n\nWORST PRODUCT: AmazonBasics AAA Performance Alkaline Batteries (36 Count) | rating=4.45 | reviews=8343\navoid because: batteries; long; don; battery; amazon; buy",
         "AmazonBasics AAA Performance Alkaline Batteries (36 Count) | Rating=4.45 | reviews=8343 | Avoid because: batteries; long; don; battery; amazon; buy"
        ],
        [
         "2",
         "E-Readers",
         "CATEGORY: E-Readers\n\nTOP 3 PRODUCTS:\n1) Kindle Voyage E-reader, 6 High-Resolution Display (300 ppi) with Adaptive Built-in Light, PagePress Sensors, Wi-Fi - Includes Special Offers | rating=4.73 | reviews=505\n   complaints: (not enough negative reviews)\n2) Kindle E-reader - White, 6 Glare-Free Touchscreen Display, Wi-Fi - Includes Special Offers | rating=4.54 | reviews=287\n   complaints: (not enough negative reviews)\n3) Kindle Oasis E-reader with Leather Charging Cover - Walnut, 6 High-Resolution Display (300 ppi), Wi-Fi - Includes Special Offers | rating=4.61 | reviews=62\n   complaints: (not enough negative reviews)\n\nWORST PRODUCT: Kindle E-reader - White, 6 Glare-Free Touchscreen Display, Wi-Fi - Includes Special Offers | rating=4.54 | reviews=287\navoid because: low ratings / frequent negatives",
         "Kindle Voyage E-reader, 6 High-Resolution Display (300 ppi) with Adaptive Built-in Light, PagePress Sensors, Wi-Fi - Includes Special Offers | rating=4.73 | reviews=505 complaints: (not enough negative reviews) Kindle Oasis E-reader with Leather Charging Cover - Walnut, 6 High-Resolution Display (300 ppi), Wi-Fi - Includes Special Offers | rating=4.54 | reviews=287 complaints: (not enough negative reviews)"
        ],
        [
         "3",
         "Fire Tablets",
         "CATEGORY: Fire Tablets\n\nTOP 3 PRODUCTS:\n1) Fire HD 8 Tablet with Alexa, 8 HD Display, 16 GB, Tangerine - with Special Offers | rating=4.60 | reviews=2445\n   complaints: tablet; just; good; bought; amazon\n2) All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Black | rating=4.58 | reviews=2370\n   complaints: tablet; just; good; amazon; apps\n3) Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB, Pink Kid-Proof Case | rating=4.53 | reviews=1702\n   complaints: tablet; charge; apps; slow; good\n\nWORST PRODUCT: Fire Tablet, 7 Display, Wi-Fi, 16 GB - Includes Special Offers, Black | rating=4.51 | reviews=1028\navoid because: tablet; apps; buy; amazon; purchased; poor",
         "Fire Tablets: 3 products: Fire HD 8 Tablet with Alexa, 8 HD Display, 16 GB, Tangerine - with Special Offers | rating=4.60 | reviews=2445 complaints: tablet; just; good; bought; amazon; purchased; poor"
        ],
        [
         "4",
         "Media & Home",
         "CATEGORY: Media & Home\n\nTOP 3 PRODUCTS:\n1) Fire TV Stick Streaming Media Player Pair Kit | rating=5.00 | reviews=6\n   complaints: (not enough negative reviews)\n2) AmazonBasics 16-Gauge Speaker Wire - 100 Feet | rating=5.00 | reviews=5\n   complaints: (not enough negative reviews)\n3) AmazonBasics External Hard Drive Case | rating=4.50 | reviews=6\n   complaints: (not enough negative reviews)",
         "The top 3 products in the Media & Home category."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>brief</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accessories</td>\n",
       "      <td>CATEGORY: Accessories\\n\\nTOP 3 PRODUCTS:\\n1) A...</td>\n",
       "      <td>Amazon 9W PowerFast Official OEM USB Charger a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batteries &amp; Household</td>\n",
       "      <td>CATEGORY: Batteries &amp; Household\\n\\nTOP 3 PRODU...</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E-Readers</td>\n",
       "      <td>CATEGORY: E-Readers\\n\\nTOP 3 PRODUCTS:\\n1) Kin...</td>\n",
       "      <td>Kindle Voyage E-reader, 6 High-Resolution Disp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire Tablets</td>\n",
       "      <td>CATEGORY: Fire Tablets\\n\\nTOP 3 PRODUCTS:\\n1) ...</td>\n",
       "      <td>Fire Tablets: 3 products: Fire HD 8 Tablet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Media &amp; Home</td>\n",
       "      <td>CATEGORY: Media &amp; Home\\n\\nTOP 3 PRODUCTS:\\n1) ...</td>\n",
       "      <td>The top 3 products in the Media &amp; Home category.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category                                              brief  \\\n",
       "0            Accessories  CATEGORY: Accessories\\n\\nTOP 3 PRODUCTS:\\n1) A...   \n",
       "1  Batteries & Household  CATEGORY: Batteries & Household\\n\\nTOP 3 PRODU...   \n",
       "2              E-Readers  CATEGORY: E-Readers\\n\\nTOP 3 PRODUCTS:\\n1) Kin...   \n",
       "3           Fire Tablets  CATEGORY: Fire Tablets\\n\\nTOP 3 PRODUCTS:\\n1) ...   \n",
       "4           Media & Home  CATEGORY: Media & Home\\n\\nTOP 3 PRODUCTS:\\n1) ...   \n",
       "\n",
       "                                             article  \n",
       "0  Amazon 9W PowerFast Official OEM USB Charger a...  \n",
       "1  AmazonBasics AAA Performance Alkaline Batterie...  \n",
       "2  Kindle Voyage E-reader, 6 High-Resolution Disp...  \n",
       "3  Fire Tablets: 3 products: Fire HD 8 Tablet wit...  \n",
       "4   The top 3 products in the Media & Home category.  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = []\n",
    "for cat in categories:\n",
    "    brief = briefs[cat]\n",
    "    article = generate_article(brief)\n",
    "    articles.append({\"category\": cat, \"brief\": brief, \"article\": article})\n",
    "\n",
    "articles_df = pd.DataFrame(articles)\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891033f8",
   "metadata": {},
   "source": [
    "## 7. Saving into a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved category_blog_posts.csv\n"
     ]
    }
   ],
   "source": [
    "articles_df.to_csv(\"category_blog_posts.csv\", index=False)\n",
    "print(\"Saved category_blog_posts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d25297",
   "metadata": {},
   "source": [
    "## 8. Gradio Test\n",
    "\n",
    "##### You can uncomment this section to run it or run with the .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02896e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 282/282 [00:02<00:00, 132.32it/s, Materializing param=shared.weight]                                                       \n",
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import re\n",
    "# import json\n",
    "# import tempfile\n",
    "# from pathlib import Path\n",
    "# import gradio as gr\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# # ---------------- Model ----------------\n",
    "# GEN_MODEL_NAME = \"google/flan-t5-base\"\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "# tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "#     GEN_MODEL_NAME,\n",
    "#     torch_dtype=dtype\n",
    "# ).to(device)\n",
    "# model.eval()\n",
    "\n",
    "# print(\"Device:\", device)\n",
    "\n",
    "# STATE = {\"df\": None}\n",
    "\n",
    "# # ---------------- Clean complaint keywords ----------------\n",
    "# STOP = {\"don\", \"didn\", \"doesn\", \"dont\", \"isn\", \"wasn\", \"weren\",\n",
    "#         \"cant\", \"couldn\", \"wouldn\", \"buy\"}\n",
    "\n",
    "# def prettify_reason(reason: str) -> str:\n",
    "#     r = (reason or \"\").strip()\n",
    "#     if not r:\n",
    "#         return \"No clear reason provided.\"\n",
    "\n",
    "#     if \";\" not in r and len(r.split()) > 5:\n",
    "#         return r\n",
    "\n",
    "#     toks = [t.strip().lower() for t in r.split(\";\") if t.strip()]\n",
    "#     toks = [t for t in toks if len(t) >= 3 and t not in STOP]\n",
    "\n",
    "#     seen = set()\n",
    "#     cleaned = []\n",
    "#     for t in toks:\n",
    "#         if t not in seen:\n",
    "#             seen.add(t)\n",
    "#             cleaned.append(t)\n",
    "\n",
    "#     cleaned = cleaned[:6]\n",
    "\n",
    "#     if not cleaned:\n",
    "#         return \"Negative feedback appears general without a clear recurring issue.\"\n",
    "\n",
    "#     return \"Negative reviews repeatedly mention: \" + \", \".join(cleaned) + \".\"\n",
    "\n",
    "# # ---------------- Brief parsing ----------------\n",
    "# def parse_brief(brief: str):\n",
    "#     b = (brief or \"\").replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").strip()\n",
    "\n",
    "#     cat = \"Category\"\n",
    "#     m = re.search(r\"^\\s*CATEGORY:\\s*(.+?)\\s*$\", b, flags=re.MULTILINE)\n",
    "#     if m:\n",
    "#         cat = m.group(1).strip()\n",
    "\n",
    "#     top3 = []\n",
    "#     top_match = re.search(\n",
    "#         r\"TOP 3 PRODUCTS:\\s*(.*?)(?:\\n\\s*WORST PRODUCT:|\\Z)\",\n",
    "#         b,\n",
    "#         flags=re.DOTALL | re.IGNORECASE\n",
    "#     )\n",
    "#     top_block = top_match.group(1).strip() if top_match else \"\"\n",
    "\n",
    "#     if top_block:\n",
    "#         chunks = re.split(r\"\\n\\s*(?=\\d+\\)\\s)\", \"\\n\" + top_block)\n",
    "#         for ch in chunks:\n",
    "#             ch = ch.strip()\n",
    "#             if not ch:\n",
    "#                 continue\n",
    "#             lines = [ln.strip() for ln in ch.split(\"\\n\") if ln.strip()]\n",
    "#             header = re.sub(r\"^\\d+\\)\\s*\", \"\", lines[0]).strip()\n",
    "#             name = header.split(\"|\")[0].strip()\n",
    "\n",
    "#             rating = None\n",
    "#             reviews = None\n",
    "#             mr = re.search(r\"rating\\s*=\\s*([0-9.]+)\", header, flags=re.IGNORECASE)\n",
    "#             mv = re.search(r\"reviews\\s*=\\s*(\\d+)\", header, flags=re.IGNORECASE)\n",
    "#             if mr: rating = float(mr.group(1))\n",
    "#             if mv: reviews = int(mv.group(1))\n",
    "\n",
    "#             complaints = \"\"\n",
    "#             for ln in lines[1:]:\n",
    "#                 if ln.lower().startswith(\"complaints:\"):\n",
    "#                     complaints = ln.split(\":\", 1)[1].strip()\n",
    "#                     break\n",
    "\n",
    "#             top3.append({\n",
    "#                 \"name\": name,\n",
    "#                 \"rating\": rating,\n",
    "#                 \"reviews\": reviews,\n",
    "#                 \"complaints\": complaints\n",
    "#             })\n",
    "\n",
    "#     worst = {\"name\": \"\", \"rating\": None, \"reviews\": None, \"reason\": \"\"}\n",
    "#     w = re.search(r\"WORST PRODUCT:\\s*(.+)\", b, flags=re.IGNORECASE)\n",
    "#     if w:\n",
    "#         wline = w.group(1).strip().split(\"\\n\")[0]\n",
    "#         worst[\"name\"] = wline.split(\"|\")[0].strip()\n",
    "#         mr = re.search(r\"rating\\s*=\\s*([0-9.]+)\", wline, flags=re.IGNORECASE)\n",
    "#         mv = re.search(r\"reviews\\s*=\\s*(\\d+)\", wline, flags=re.IGNORECASE)\n",
    "#         if mr: worst[\"rating\"] = float(mr.group(1))\n",
    "#         if mv: worst[\"reviews\"] = int(mv.group(1))\n",
    "\n",
    "#     r = re.search(r\"avoid because:\\s*(.+)\\s*$\", b, flags=re.IGNORECASE | re.MULTILINE)\n",
    "#     if r:\n",
    "#         worst[\"reason\"] = r.group(1).strip()\n",
    "\n",
    "#     return cat, top3, worst\n",
    "\n",
    "# # ---------------- Summary generation ----------------\n",
    "# @torch.inference_mode()\n",
    "# def generate_summary_from_brief(brief: str) -> str:\n",
    "#     cat, top3, worst = parse_brief(brief)\n",
    "\n",
    "#     lines = [f\"Category: {cat}.\"]\n",
    "#     for p in top3:\n",
    "#         lines.append(\n",
    "#             f\"{p['name']} has rating {p['rating']} from {p['reviews']} reviews.\"\n",
    "#         )\n",
    "\n",
    "#     if worst[\"name\"]:\n",
    "#         lines.append(\n",
    "#             f\"The lowest rated is {worst['name']} with rating {worst['rating']} from {worst['reviews']} reviews.\"\n",
    "#         )\n",
    "\n",
    "#     facts = \"\\n\".join(lines)\n",
    "\n",
    "#     prompt = f\"\"\"Write 2 short natural paragraphs for shoppers.\n",
    "\n",
    "# Use ONLY the facts below.\n",
    "\n",
    "# FACTS:\n",
    "# {facts}\n",
    "# \"\"\"\n",
    "\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=384).to(device)\n",
    "\n",
    "#     out = model.generate(\n",
    "#         **inputs,\n",
    "#         max_new_tokens=140,\n",
    "#         do_sample=True,\n",
    "#         temperature=0.6,\n",
    "#         top_p=0.9,\n",
    "#         repetition_penalty=1.15,\n",
    "#         use_cache=False,\n",
    "#     )\n",
    "\n",
    "#     return tokenizer.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "# # ---------------- Markdown builder ----------------\n",
    "# def build_full_markdown(brief: str) -> str:\n",
    "#     cat, top3, worst = parse_brief(brief)\n",
    "#     summary = generate_summary_from_brief(brief)\n",
    "\n",
    "#     md = [f\"# {cat}\", \"\", summary, \"\", \"## Top Picks\"]\n",
    "\n",
    "#     for p in top3:\n",
    "#         md.append(\n",
    "#             f\"**{p['name']}**  \\n\"\n",
    "#             f\"Rating: {p['rating']} â€¢ Reviews: {p['reviews']}  \\n\"\n",
    "#             f\"Complaints: {p['complaints']}\"\n",
    "#         )\n",
    "\n",
    "#     md.append(\"\\n## Avoid / Lowest Rated\")\n",
    "\n",
    "#     if worst[\"name\"]:\n",
    "#         md.append(\n",
    "#             f\"**{worst['name']}**  \\n\"\n",
    "#             f\"Rating: {worst['rating']} â€¢ Reviews: {worst['reviews']}  \\n\"\n",
    "#             f\"Complaint signal: {prettify_reason(worst['reason'])}\"\n",
    "#         )\n",
    "\n",
    "#     return \"\\n\\n\".join(md)\n",
    "\n",
    "# # ---------------- JSON Export ----------------\n",
    "# def export_json():\n",
    "#     df = STATE[\"df\"]\n",
    "#     if df is None:\n",
    "#         raise ValueError(\"No CSV loaded.\")\n",
    "\n",
    "#     cluster_summaries = {}\n",
    "#     product_summaries = {}\n",
    "\n",
    "#     for _, row in df.iterrows():\n",
    "#         category = str(row[\"category\"])\n",
    "#         brief = str(row[\"brief\"])\n",
    "\n",
    "#         cluster_summaries[category] = build_full_markdown(brief)\n",
    "\n",
    "#         cat, top3, worst = parse_brief(brief)\n",
    "\n",
    "#         for p in top3:\n",
    "#             product_summaries[p[\"name\"]] = {\n",
    "#                 \"cluster\": category,\n",
    "#                 \"stats\": {\n",
    "#                     \"total_reviews\": p[\"reviews\"],\n",
    "#                     \"avg_rating\": p[\"rating\"],\n",
    "#                     \"pct_positive\": None,\n",
    "#                     \"pct_negative\": None,\n",
    "#                     \"pct_neutral\": None\n",
    "#                 },\n",
    "#                 \"summary\": f\"{p['name']} has rating {p['rating']} from {p['reviews']} reviews.\"\n",
    "#             }\n",
    "\n",
    "#     export_obj = {\n",
    "#         \"provider\": \"huggingface\",\n",
    "#         \"model\": \"google/flan-t5-base\",\n",
    "#         \"cluster_summaries\": cluster_summaries,\n",
    "#         \"product_summaries\": product_summaries\n",
    "#     }\n",
    "\n",
    "#     tmpdir = tempfile.mkdtemp()\n",
    "#     path = Path(tmpdir) / \"export.json\"\n",
    "#     path.write_text(json.dumps(export_obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "#     return str(path)\n",
    "\n",
    "# # ---------------- Gradio UI ----------------\n",
    "# with gr.Blocks(title=\"Category Blog Generator\") as demo:\n",
    "#     gr.Markdown(\"# Category Blog Generator\")\n",
    "\n",
    "#     csv_file = gr.File(file_types=[\".csv\"])\n",
    "#     load_btn = gr.Button(\"Load CSV\")\n",
    "\n",
    "#     category_dd = gr.Dropdown(label=\"Category\")\n",
    "#     gen_btn = gr.Button(\"Generate Summary\")\n",
    "\n",
    "#     output_md = gr.Markdown()\n",
    "\n",
    "#     export_btn = gr.Button(\"Export JSON\")\n",
    "#     export_file = gr.File()\n",
    "\n",
    "#     def load_csv(file):\n",
    "#         df = pd.read_csv(file.name)\n",
    "#         STATE[\"df\"] = df\n",
    "#         categories = sorted(df[\"category\"].unique())\n",
    "#         return gr.Dropdown(choices=categories, value=categories[0])\n",
    "\n",
    "#     def generate(category):\n",
    "#         df = STATE[\"df\"]\n",
    "#         row = df[df[\"category\"] == category].iloc[0]\n",
    "#         return build_full_markdown(row[\"brief\"])\n",
    "\n",
    "#     load_btn.click(load_csv, inputs=[csv_file], outputs=[category_dd])\n",
    "#     gen_btn.click(generate, inputs=[category_dd], outputs=[output_md])\n",
    "#     export_btn.click(export_json, outputs=[export_file])\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catblog-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
